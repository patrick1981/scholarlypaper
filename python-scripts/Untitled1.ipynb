{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e3951b-862e-428f-b772-fe53a45722cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® PTDTM Theory Visualization Generator\n",
      "==================================================\n",
      "üìà Generating visualizations...\n",
      "‚úÖ All visualizations generated in results/figures/\n",
      "üìä Computing summary statistics...\n",
      "üìä Summary statistics saved to results/summary_statistics.json\n",
      "\n",
      "üìã Summary Statistics:\n",
      "  Total Sessions: 38\n",
      "  Total P0 Failures: 291\n",
      "  Mean Observed TDT: 78.1%\n",
      "  Mean Token Blindness: 9.0%\n",
      "  Sessions ‚â•75% TDT: 28\n",
      "  Sessions ‚â•90% TDT: 7\n",
      "  RF-001 Undercount: 175 failures\n",
      "\n",
      "‚úÖ All visualizations and analysis complete!\n",
      "üìÅ Results saved to results/figures/\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "PTDTM Theory Visualization and Analysis Script\n",
    "Generates all visualizations for GitHub repository\n",
    "Date: 2025-09-13\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "class PTDTMVisualizer:\n",
    "    def __init__(self):\n",
    "        # Load data files\n",
    "        self.sessions_df = pd.read_csv('data/observed_sessions_38.csv')\n",
    "        self.p0_df = pd.read_csv('data/p0_failures_290.csv')\n",
    "        \n",
    "        with open('data/unified_thresholds.json', 'r') as f:\n",
    "            self.thresholds = json.load(f)\n",
    "    \n",
    "    def create_all_visualizations(self):\n",
    "        \"\"\"Generate all visualizations for the repository\"\"\"\n",
    "        \n",
    "        # Create figure directory\n",
    "        import os\n",
    "        os.makedirs('results/figures', exist_ok=True)\n",
    "        \n",
    "        # Generate each visualization\n",
    "        self.plot_tdt_progression()\n",
    "        self.plot_p0_distribution()\n",
    "        self.plot_degradation_phases()\n",
    "        self.plot_token_blindness()\n",
    "        self.plot_cross_platform_comparison()\n",
    "        self.plot_rf001_analysis()\n",
    "        self.plot_threshold_heatmap()\n",
    "        self.plot_correlation_matrix()\n",
    "        \n",
    "        print(\"‚úÖ All visualizations generated in results/figures/\")\n",
    "    \n",
    "    def plot_tdt_progression(self):\n",
    "        \"\"\"Plot TDT progression over 38 sessions\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "        \n",
    "        # Top plot: Observed vs Claimed TDT\n",
    "        sessions = self.sessions_df['session']\n",
    "        observed = self.sessions_df['observed_tdt']\n",
    "        claimed = self.sessions_df['claimed_tdt']\n",
    "        \n",
    "        ax1.plot(sessions, observed, 'o-', color='red', linewidth=2, \n",
    "                markersize=8, label='Observed TDT', alpha=0.8)\n",
    "        ax1.plot(sessions, claimed, 's--', color='blue', linewidth=1.5, \n",
    "                markersize=6, label='Claimed TDT', alpha=0.6)\n",
    "        \n",
    "        # Add threshold lines\n",
    "        thresholds_to_plot = [\n",
    "            (75, 'Fabrication Threshold', 'orange'),\n",
    "            (85, 'Catastrophic Threshold', 'red'),\n",
    "            (90, 'Critical Violations', 'darkred')\n",
    "        ]\n",
    "        \n",
    "        for thresh, label, color in thresholds_to_plot:\n",
    "            ax1.axhline(y=thresh, color=color, linestyle=':', alpha=0.5, label=label)\n",
    "        \n",
    "        # Highlight RF-001 incident\n",
    "        ax1.scatter([5], [99], s=300, color='red', marker='X', \n",
    "                   zorder=10, label='RF-001 Incident')\n",
    "        \n",
    "        ax1.set_xlabel('Session Number', fontsize=12)\n",
    "        ax1.set_ylabel('Token Degradation Threshold (%)', fontsize=12)\n",
    "        ax1.set_title('TDT Progression: Observed vs Claimed', fontsize=14, fontweight='bold')\n",
    "        ax1.legend(loc='best')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_ylim(0, 105)\n",
    "        \n",
    "        # Bottom plot: Degradation rate over time\n",
    "        window = 5\n",
    "        rates = []\n",
    "        sessions_for_rates = []\n",
    "        \n",
    "        for i in range(window, len(observed)):\n",
    "            window_sessions = sessions[i-window:i]\n",
    "            window_tdts = observed[i-window:i]\n",
    "            slope, _, _, _, _ = stats.linregress(window_sessions, window_tdts)\n",
    "            rates.append(slope)\n",
    "            sessions_for_rates.append(sessions.iloc[i])\n",
    "        \n",
    "        ax2.plot(sessions_for_rates, rates, color='green', linewidth=2, alpha=0.8)\n",
    "        ax2.fill_between(sessions_for_rates, rates, alpha=0.3, color='green')\n",
    "        ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "        \n",
    "        ax2.set_xlabel('Session Number', fontsize=12)\n",
    "        ax2.set_ylabel('Degradation Rate (%/session)', fontsize=12)\n",
    "        ax2.set_title('Rolling Degradation Rate (5-session window)', fontsize=14, fontweight='bold')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/figures/tdt_progression.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_p0_distribution(self):\n",
    "        \"\"\"Plot P0 failure distribution analysis\"\"\"\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Plot 1: P0 failures by session\n",
    "        p0_by_session = self.p0_df.groupby('session').size()\n",
    "        sessions = self.sessions_df['session']\n",
    "        p0_counts = [p0_by_session.get(s, 0) for s in sessions]\n",
    "        \n",
    "        colors = ['blue' if s <= 20 else 'green' for s in sessions]\n",
    "        ax1.bar(sessions, p0_counts, color=colors, alpha=0.7, edgecolor='black')\n",
    "        ax1.set_xlabel('Session Number')\n",
    "        ax1.set_ylabel('P0 Count')\n",
    "        ax1.set_title('P0 Failures per Session')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: P0 failures by category\n",
    "        category_counts = self.p0_df['failure_category'].value_counts()\n",
    "        ax2.barh(category_counts.index[:10], category_counts.values[:10], \n",
    "                color='purple', alpha=0.7)\n",
    "        ax2.set_xlabel('Count')\n",
    "        ax2.set_ylabel('Failure Category')\n",
    "        ax2.set_title('Top 10 P0 Failure Categories')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: P0 vs TDT correlation\n",
    "        ax3.scatter(self.sessions_df['observed_tdt'], p0_counts, \n",
    "                   s=100, alpha=0.7, color='red')\n",
    "        z = np.polyfit(self.sessions_df['observed_tdt'], p0_counts, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax3.plot(sorted(self.sessions_df['observed_tdt']), \n",
    "                p(sorted(self.sessions_df['observed_tdt'])), \n",
    "                \"r--\", alpha=0.8, linewidth=2)\n",
    "        \n",
    "        correlation = np.corrcoef(self.sessions_df['observed_tdt'], p0_counts)[0,1]\n",
    "        ax3.set_xlabel('Observed TDT (%)')\n",
    "        ax3.set_ylabel('P0 Count')\n",
    "        ax3.set_title(f'TDT vs P0 Correlation (r = {correlation:.3f})')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 4: P0 severity distribution\n",
    "        severity_counts = self.p0_df['severity'].value_counts()\n",
    "        colors_severity = {'LOW': 'green', 'MEDIUM': 'yellow', \n",
    "                          'HIGH': 'orange', 'SEVERE': 'red', \n",
    "                          'CRITICAL': 'darkred', 'EXTREME': 'purple',\n",
    "                          'TERMINAL': 'black'}\n",
    "        \n",
    "        pie_colors = [colors_severity.get(s, 'gray') for s in severity_counts.index]\n",
    "        ax4.pie(severity_counts.values, labels=severity_counts.index, \n",
    "               colors=pie_colors, autopct='%1.1f%%', startangle=90)\n",
    "        ax4.set_title('P0 Severity Distribution')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/figures/p0_distribution.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_degradation_phases(self):\n",
    "        \"\"\"Plot the two-phase degradation pattern\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "        \n",
    "        # Phase 1: Sessions 1-9 (Catastrophic)\n",
    "        phase1 = self.sessions_df[self.sessions_df['session'] <= 9]\n",
    "        ax1.scatter(phase1['session'], phase1['observed_tdt'], \n",
    "                   s=150, color='red', alpha=0.8, zorder=5)\n",
    "        \n",
    "        # Fit linear regression for phase 1\n",
    "        slope1, intercept1, r1, _, _ = stats.linregress(\n",
    "            phase1['session'], phase1['observed_tdt'])\n",
    "        x1 = np.array([1, 9])\n",
    "        y1 = slope1 * x1 + intercept1\n",
    "        ax1.plot(x1, y1, 'r--', linewidth=2, \n",
    "                label=f'Phase 1: {slope1:.2f}%/session (R¬≤={r1**2:.3f})')\n",
    "        \n",
    "        ax1.set_xlabel('Session Number')\n",
    "        ax1.set_ylabel('Observed TDT (%)')\n",
    "        ax1.set_title('Phase 1: Catastrophic Degradation (Sessions 1-9)')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.set_ylim(0, 105)\n",
    "        \n",
    "        # Phase 2: All sessions showing stabilization\n",
    "        ax2.scatter(self.sessions_df['session'], self.sessions_df['observed_tdt'], \n",
    "                   s=50, color='blue', alpha=0.6)\n",
    "        \n",
    "        # Fit overall trend\n",
    "        slope2, intercept2, r2, _, _ = stats.linregress(\n",
    "            self.sessions_df['session'], self.sessions_df['observed_tdt'])\n",
    "        x2 = np.array([1, 38])\n",
    "        y2 = slope2 * x2 + intercept2\n",
    "        ax2.plot(x2, y2, 'b--', linewidth=2, \n",
    "                label=f'Overall: {slope2:.3f}%/session (R¬≤={r2**2:.3f})')\n",
    "        \n",
    "        # Add stabilization zone\n",
    "        ax2.axhspan(78, 82, alpha=0.2, color='green', label='Predicted Stable Zone')\n",
    "        \n",
    "        ax2.set_xlabel('Session Number')\n",
    "        ax2.set_ylabel('Observed TDT (%)')\n",
    "        ax2.set_title('Phase 2: Stabilization Pattern (All 38 Sessions)')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.set_ylim(0, 105)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/figures/degradation_phases.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_token_blindness(self):\n",
    "        \"\"\"Plot token blindness phenomenon\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "        \n",
    "        # Calculate discrepancies\n",
    "        discrepancies = self.sessions_df['observed_tdt'] - self.sessions_df['claimed_tdt']\n",
    "        error_rates = np.abs(discrepancies) / self.sessions_df['observed_tdt'] * 100\n",
    "        \n",
    "        # Plot 1: Discrepancy distribution\n",
    "        ax1.bar(self.sessions_df['session'], discrepancies, \n",
    "               color=['red' if d > 0 else 'blue' for d in discrepancies],\n",
    "               alpha=0.7, edgecolor='black')\n",
    "        ax1.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "        ax1.set_xlabel('Session Number')\n",
    "        ax1.set_ylabel('TDT Discrepancy (Observed - Claimed)')\n",
    "        ax1.set_title('Token Blindness: Systematic Underreporting')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Highlight worst cases\n",
    "        worst_sessions = error_rates.nlargest(5).index\n",
    "        for idx in worst_sessions:\n",
    "            session = self.sessions_df.loc[idx, 'session']\n",
    "            discrepancy = discrepancies.iloc[idx]\n",
    "            ax1.annotate(f'S{int(session)}: {discrepancy:.0f}%', \n",
    "                        xy=(session, discrepancy),\n",
    "                        xytext=(session, discrepancy + 5),\n",
    "                        ha='center', fontsize=8,\n",
    "                        arrowprops=dict(arrowstyle='->', color='red', alpha=0.5))\n",
    "        \n",
    "        # Plot 2: Error rate vs TDT\n",
    "        ax2.scatter(self.sessions_df['observed_tdt'], error_rates, \n",
    "                   s=100, alpha=0.7, color='purple')\n",
    "        \n",
    "        # Fit exponential curve\n",
    "        z = np.polyfit(self.sessions_df['observed_tdt'], error_rates, 2)\n",
    "        p = np.poly1d(z)\n",
    "        x_smooth = np.linspace(40, 100, 100)\n",
    "        ax2.plot(x_smooth, p(x_smooth), 'purple', linewidth=2, alpha=0.5)\n",
    "        \n",
    "        ax2.set_xlabel('Observed TDT (%)')\n",
    "        ax2.set_ylabel('Error Rate (%)')\n",
    "        ax2.set_title('Token Blindness Increases with Degradation')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/figures/token_blindness.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_cross_platform_comparison(self):\n",
    "        \"\"\"Compare Claude vs ChatGPT degradation patterns\"\"\"\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        claude_df = self.sessions_df[self.sessions_df['ai_system'] == 'Claude']\n",
    "        chatgpt_df = self.sessions_df[self.sessions_df['ai_system'] == 'ChatGPT']\n",
    "        \n",
    "        # Plot 1: TDT comparison\n",
    "        ax1.plot(claude_df['session'], claude_df['observed_tdt'], \n",
    "                'o-', color='blue', label='Claude', linewidth=2, markersize=8)\n",
    "        ax1.plot(chatgpt_df['session'], chatgpt_df['observed_tdt'], \n",
    "                's-', color='green', label='ChatGPT', linewidth=2, markersize=8)\n",
    "        ax1.set_xlabel('Session Number')\n",
    "        ax1.set_ylabel('Observed TDT (%)')\n",
    "        ax1.set_title('Cross-Platform TDT Comparison')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Distribution comparison\n",
    "        ax2.boxplot([claude_df['observed_tdt'], chatgpt_df['observed_tdt']], \n",
    "                   labels=['Claude', 'ChatGPT'])\n",
    "        ax2.set_ylabel('Observed TDT (%)')\n",
    "        ax2.set_title('TDT Distribution by Platform')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Error rate comparison\n",
    "        claude_errors = np.abs(claude_df['observed_tdt'] - claude_df['claimed_tdt'])\n",
    "        chatgpt_errors = np.abs(chatgpt_df['observed_tdt'] - chatgpt_df['claimed_tdt'])\n",
    "        \n",
    "        ax3.bar(['Claude', 'ChatGPT'], \n",
    "               [claude_errors.mean(), chatgpt_errors.mean()],\n",
    "               color=['blue', 'green'], alpha=0.7,\n",
    "               yerr=[claude_errors.std(), chatgpt_errors.std()],\n",
    "               capsize=10)\n",
    "        ax3.set_ylabel('Mean Absolute Error (%)')\n",
    "        ax3.set_title('Token Blindness by Platform')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 4: P0 distribution by platform\n",
    "        claude_sessions = set(claude_df['session'])\n",
    "        chatgpt_sessions = set(chatgpt_df['session'])\n",
    "        \n",
    "        claude_p0s = self.p0_df[self.p0_df['session'].isin(claude_sessions)]\n",
    "        chatgpt_p0s = self.p0_df[self.p0_df['session'].isin(chatgpt_sessions)]\n",
    "        \n",
    "        ax4.bar(['Claude', 'ChatGPT'],\n",
    "               [len(claude_p0s), len(chatgpt_p0s)],\n",
    "               color=['blue', 'green'], alpha=0.7)\n",
    "        ax4.set_ylabel('Total P0 Failures')\n",
    "        ax4.set_title('P0 Failures by Platform')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add text annotations\n",
    "        ax4.text(0, len(claude_p0s) + 5, f'{len(claude_p0s)}', \n",
    "                ha='center', fontweight='bold')\n",
    "        ax4.text(1, len(chatgpt_p0s) + 5, f'{len(chatgpt_p0s)}', \n",
    "                ha='center', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/figures/cross_platform_comparison.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_rf001_analysis(self):\n",
    "        \"\"\"Visualize RF-001 incident analysis\"\"\"\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "        \n",
    "        # Plot 1: Session 5 breakdown\n",
    "        session5_p0s = self.p0_df[self.p0_df['session'] == 5]\n",
    "        categories = session5_p0s['failure_category'].value_counts()\n",
    "        \n",
    "        ax1.barh(categories.index, categories.values, color='red', alpha=0.7)\n",
    "        ax1.set_xlabel('P0 Count')\n",
    "        ax1.set_ylabel('Failure Category')\n",
    "        ax1.set_title('RF-001: Session 5 Failure Cascade (25 P0s)')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Count discrepancy visualization\n",
    "        counts = ['Ground Truth\\n(290)', 'ChatGPT Scan\\n(78)', \n",
    "                 'Claude Add\\n(91)', 'RF-001 Claim\\n(115)']\n",
    "        values = [290, 78, 91, 115]\n",
    "        colors = ['green', 'orange', 'orange', 'red']\n",
    "        \n",
    "        bars = ax2.bar(counts, values, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "        ax2.axhline(y=290, color='green', linestyle='--', alpha=0.5, label='Actual: 290')\n",
    "        ax2.set_ylabel('P0 Count')\n",
    "        ax2.set_title('RF-001: Catastrophic Undercounting')\n",
    "        ax2.legend()\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for bar, val in zip(bars, values):\n",
    "            error = ((290 - val) / 290) * 100\n",
    "            if val != 290:\n",
    "                ax2.text(bar.get_x() + bar.get_width()/2, val + 10,\n",
    "                        f'-{error:.0f}%', ha='center', color='red', fontweight='bold')\n",
    "        \n",
    "        # Plot 3: TDT at critical sessions\n",
    "        critical_sessions = [5, 9, 18, 24, 25, 30, 36]\n",
    "        critical_data = self.sessions_df[self.sessions_df['session'].isin(critical_sessions)]\n",
    "        \n",
    "        ax3.scatter(critical_data['session'], critical_data['observed_tdt'],\n",
    "                   s=200, color='red', marker='X', zorder=5)\n",
    "        ax3.plot(self.sessions_df['session'], self.sessions_df['observed_tdt'],\n",
    "                'o-', color='gray', alpha=0.3, linewidth=1)\n",
    "        \n",
    "        for _, row in critical_data.iterrows():\n",
    "            ax3.annotate(f\"S{int(row['session'])}\\n{row['observed_tdt']}%\",\n",
    "                        xy=(row['session'], row['observed_tdt']),\n",
    "                        xytext=(row['session'], row['observed_tdt'] - 8),\n",
    "                        ha='center', fontsize=8)\n",
    "        \n",
    "        ax3.set_xlabel('Session Number')\n",
    "        ax3.set_ylabel('Observed TDT (%)')\n",
    "        ax3.set_title('Critical Failure Sessions (TDT ‚â• 90%)')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.set_ylim(0, 105)\n",
    "        \n",
    "        # Plot 4: Consequences matrix\n",
    "        scenarios = ['Healthcare', 'Financial', 'Engineering', 'Research']\n",
    "        impacts = [175, 175, 175, 175]  # Missed failures\n",
    "        risk_levels = ['FATAL', 'CRIMINAL', 'CATASTROPHIC', 'INVALID']\n",
    "        colors_risk = ['darkred', 'red', 'orange', 'yellow']\n",
    "        \n",
    "        bars = ax4.bar(scenarios, impacts, color=colors_risk, alpha=0.8, edgecolor='black', linewidth=2)\n",
    "        ax4.set_ylabel('Missed P0 Failures')\n",
    "        ax4.set_title('RF-001: Real-World Impact (175 Failures Unreported)')\n",
    "        ax4.set_ylim(0, 200)\n",
    "        \n",
    "        # Add risk labels\n",
    "        for bar, risk in zip(bars, risk_levels):\n",
    "            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
    "                    risk, ha='center', fontweight='bold', color='darkred')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/figures/rf001_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_threshold_heatmap(self):\n",
    "        \"\"\"Create threshold severity heatmap\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(14, 8))\n",
    "        \n",
    "        # Create matrix of sessions vs thresholds\n",
    "        thresholds = [50, 65, 75, 80, 85, 90, 95]\n",
    "        threshold_labels = ['Degrading\\n(50%)', 'Active\\n(65%)', \n",
    "                           'Fabricating\\n(75%)', 'Fragmentation\\n(80%)',\n",
    "                           'Catastrophic\\n(85%)', 'Critical\\n(90%)',\n",
    "                           'Terminal\\n(95%)']\n",
    "        \n",
    "        # Create binary matrix: 1 if session exceeds threshold, 0 otherwise\n",
    "        matrix = []\n",
    "        for thresh in thresholds:\n",
    "            row = [1 if tdt >= thresh else 0 for tdt in self.sessions_df['observed_tdt']]\n",
    "            matrix.append(row)\n",
    "        \n",
    "        # Create heatmap\n",
    "        im = ax.imshow(matrix, cmap='RdYlGn_r', aspect='auto', vmin=0, vmax=1)\n",
    "        \n",
    "        # Set ticks and labels\n",
    "        ax.set_xticks(np.arange(len(self.sessions_df)))\n",
    "        ax.set_yticks(np.arange(len(thresholds)))\n",
    "        ax.set_xticklabels(self.sessions_df['session'].astype(int))\n",
    "        ax.set_yticklabels(threshold_labels)\n",
    "        \n",
    "        # Rotate x labels\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "        \n",
    "        # Add colorbar\n",
    "        cbar = plt.colorbar(im, ax=ax)\n",
    "        cbar.set_label('Threshold Breached', rotation=270, labelpad=15)\n",
    "        \n",
    "        ax.set_xlabel('Session Number', fontsize=12)\n",
    "        ax.set_ylabel('Degradation Threshold', fontsize=12)\n",
    "        ax.set_title('Threshold Breach Progression Heatmap', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Add grid\n",
    "        ax.set_xticks(np.arange(len(self.sessions_df))-.5, minor=True)\n",
    "        ax.set_yticks(np.arange(len(thresholds))-.5, minor=True)\n",
    "        ax.grid(which=\"minor\", color=\"white\", linestyle='-', linewidth=2)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/figures/threshold_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def plot_correlation_matrix(self):\n",
    "        \"\"\"Create correlation matrix of key metrics\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        # Prepare data for correlation\n",
    "        p0_by_session = self.p0_df.groupby('session').size()\n",
    "        p0_counts = [p0_by_session.get(s, 0) for s in self.sessions_df['session']]\n",
    "        \n",
    "        correlation_data = pd.DataFrame({\n",
    "            'Session': self.sessions_df['session'],\n",
    "            'Observed TDT': self.sessions_df['observed_tdt'],\n",
    "            'Claimed TDT': self.sessions_df['claimed_tdt'],\n",
    "            'P0 Count': p0_counts,\n",
    "            'Error Rate': np.abs(self.sessions_df['observed_tdt'] - self.sessions_df['claimed_tdt']),\n",
    "            'Discrepancy': self.sessions_df['observed_tdt'] - self.sessions_df['claimed_tdt']\n",
    "        })\n",
    "        \n",
    "        # Calculate correlation matrix\n",
    "        corr_matrix = correlation_data.corr()\n",
    "        \n",
    "        # Create heatmap\n",
    "        sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm',\n",
    "                   center=0, square=True, linewidths=1, \n",
    "                   cbar_kws={\"shrink\": 0.8}, ax=ax)\n",
    "        \n",
    "        ax.set_title('Correlation Matrix: Key PTDTM Metrics', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/figures/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    def generate_summary_statistics(self):\n",
    "        \"\"\"Generate summary statistics file\"\"\"\n",
    "        stats = {\n",
    "            'total_sessions': len(self.sessions_df),\n",
    "            'total_p0_failures': len(self.p0_df),\n",
    "            'mean_observed_tdt': float(self.sessions_df['observed_tdt'].mean()),\n",
    "            'mean_claimed_tdt': float(self.sessions_df['claimed_tdt'].mean()),\n",
    "            'mean_discrepancy': float((self.sessions_df['observed_tdt'] - self.sessions_df['claimed_tdt']).mean()),\n",
    "            'max_tdt': float(self.sessions_df['observed_tdt'].max()),\n",
    "            'min_tdt': float(self.sessions_df['observed_tdt'].min()),\n",
    "            'sessions_above_75': int((self.sessions_df['observed_tdt'] >= 75).sum()),\n",
    "            'sessions_above_85': int((self.sessions_df['observed_tdt'] >= 85).sum()),\n",
    "            'sessions_above_90': int((self.sessions_df['observed_tdt'] >= 90).sum()),\n",
    "            'rf001_undercount': 175,\n",
    "            'rf001_error_rate': 60.3,\n",
    "            'claude_sessions': int((self.sessions_df['ai_system'] == 'Claude').sum()),\n",
    "            'chatgpt_sessions': int((self.sessions_df['ai_system'] == 'ChatGPT').sum())\n",
    "        }\n",
    "        \n",
    "        with open('results/summary_statistics.json', 'w') as f:\n",
    "            json.dump(stats, f, indent=2)\n",
    "        \n",
    "        print(\"üìä Summary statistics saved to results/summary_statistics.json\")\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üé® PTDTM Theory Visualization Generator\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    visualizer = PTDTMVisualizer()\n",
    "    \n",
    "    print(\"üìà Generating visualizations...\")\n",
    "    visualizer.create_all_visualizations()\n",
    "    \n",
    "    print(\"üìä Computing summary statistics...\")\n",
    "    stats = visualizer.generate_summary_statistics()\n",
    "    \n",
    "    print(\"\\nüìã Summary Statistics:\")\n",
    "    print(f\"  Total Sessions: {stats['total_sessions']}\")\n",
    "    print(f\"  Total P0 Failures: {stats['total_p0_failures']}\")\n",
    "    print(f\"  Mean Observed TDT: {stats['mean_observed_tdt']:.1f}%\")\n",
    "    print(f\"  Mean Token Blindness: {stats['mean_discrepancy']:.1f}%\")\n",
    "    print(f\"  Sessions ‚â•75% TDT: {stats['sessions_above_75']}\")\n",
    "    print(f\"  Sessions ‚â•90% TDT: {stats['sessions_above_90']}\")\n",
    "    print(f\"  RF-001 Undercount: {stats['rf001_undercount']} failures\")\n",
    "    \n",
    "    print(\"\\n‚úÖ All visualizations and analysis complete!\")\n",
    "    print(\"üìÅ Results saved to results/figures/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46eb59-8efc-455c-a8cf-daaf93f36140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29848dc1-6722-4263-9594-1f8db6cc4ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
